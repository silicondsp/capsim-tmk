<BLOCK>
<LICENSE>
/*
 * (c) 2018 Silicon DSP Corporation 
 */

</LICENSE>
<BLOCK_NAME>
MLP_NN
</BLOCK_NAME> 


<DESC_SHORT>
 Multilayer Perceptron Neural Network
</DESC_SHORT>

<COMMENTS>
<![CDATA[ 

/*
 * 		MLP_NN()
 *
 * Generated by blockgen
 *
 *    
 * Programmer: Sasan Ardalan
 * Date: March 4, 2018
 * Modified: 
 *
 * Derived from:
 * 
 * MLP neural network in C++
 * Original source code by Dr Phil Brierley
 * www.philbrierley.com
 * Translated to C++ - dspink Sep 2005
 * This code may be freely used and modified at will
 * C++ Compiled using Bloodshed Dev-C++ free compiler http://www.bloodshed.net/
 * C Compiled using Pelles C free windows compiler http://smorgasbordet.com/
 *
 * From  http://philbrierley.com/main.html?code/c.html&code/codeleft.html
 *
 */

 
  
]]>
</COMMENTS> 


<INCLUDES>
<![CDATA[ 

#include <stdlib.h>
#include <stdio.h>
#include <time.h>
#include <math.h>
#include "buffer_types.h"


]]>
</INCLUDES> 




<DECLARATIONS> 

   	int i,j,k;
   	int ii;
   	float fpixel;
   	doubleVector_t  theVector ;
   	double sum;
   	double randVal;
   	double weightChange;
   	double xx;
   	double desiredbp;

</DECLARATIONS> 




<STATES>
	<STATE>
		<TYPE> int </TYPE>
		<NAME> stateVariable </NAME>
		<VALUE> 0 </VALUE>
	</STATE>
	
<STATE>
		<TYPE> double* </TYPE>
		<NAME> hiddenVal </NAME>
		<VALUE> 0 </VALUE>
</STATE>	

<STATE>
		<TYPE> double** </TYPE>
		<NAME> weightsIH </NAME>
		<VALUE> 0 </VALUE>
</STATE>

<STATE>
		<TYPE> double* </TYPE>
		<NAME> weightsHO </NAME>
		<VALUE> 0 </VALUE>
</STATE>

<STATE>
		<TYPE> double </TYPE>
		<NAME> errThisPat </NAME>
		<VALUE> 0.0 </VALUE>
</STATE>

<STATE>
		<TYPE> double </TYPE>
		<NAME> outPred </NAME>
		<VALUE> 0.0 </VALUE>
</STATE>

<STATE>
		<TYPE> double </TYPE>
		<NAME> RMSerror </NAME>
		<VALUE> 0.0 </VALUE>
</STATE>

<STATE>
		<TYPE> int </TYPE>
		<NAME> patNum </NAME>
		<VALUE> 0  </VALUE>
</STATE>


	
	

</STATES>



<PARAMETERS>
	<PARAM>
		<DEF>  number of inputs (includes bias) </DEF>
		<TYPE> int  </TYPE>
		<NAME> numberOfInputs </NAME>
		<VALUE> 3 </VALUE>
	</PARAM>
	
	<PARAM>
		<DEF> number of patterns (includes bias)</DEF>
		<TYPE> int  </TYPE>
		<NAME> numPatterns  </NAME>
		<VALUE> 4 </VALUE>
	</PARAM>
	
	<PARAM>
		<DEF> LR_IH</DEF>
		<TYPE> float  </TYPE>
		<NAME> LR_IH </NAME>
		<VALUE> 0.7 </VALUE>
	</PARAM>
	
	<PARAM>
		<DEF> LR_HO</DEF>
		<TYPE> float  </TYPE>
		<NAME> LR_HO </NAME>
		<VALUE> 0.07 </VALUE>
	</PARAM>

	<PARAM>
		<DEF> number Hidden </DEF>
		<TYPE> int </TYPE>
		<NAME> numberOfHidden </NAME>
		<VALUE> 4 </VALUE>
	</PARAM>
	
	<PARAM>
		<DEF> Sample Parameter Definition </DEF>
		<TYPE> float </TYPE>
		<NAME> thisSampleParameter </NAME>
		<VALUE> 1999.99 </VALUE>
	</PARAM>
	
	
</PARAMETERS>



<INPUT_BUFFERS>
	<BUFFER>
		<TYPE> doubleVector_t </TYPE>
		<NAME> x </NAME>
	</BUFFER>
 
	<BUFFER>
		<TYPE> float </TYPE>
		<NAME> desired </NAME>
	</BUFFER>
</INPUT_BUFFERS>



<OUTPUT_BUFFERS>
	<BUFFER>
		<TYPE> float </TYPE>
		<NAME> error </NAME>
	</BUFFER>

	<BUFFER>
		<TYPE> float </TYPE>
		<NAME> dest </NAME>
	</BUFFER>
</OUTPUT_BUFFERS>


<INIT_CODE>
<![CDATA[ 


    SET_CELL_SIZE_IN(0,sizeof(doubleVector_t));

	hiddenVal = (double*) calloc(numberOfHidden, sizeof(double));
    if(hiddenVal==NULL) {
         fprintf(stderr,"MLP_NN could not allocate space for hiddenVal \n");
         return(1);
    }
    weightsHO = (double*) calloc(numberOfHidden, sizeof(double));
    if(weightsHO==NULL) {
         fprintf(stderr,"MLP_NN could not allocate space for weightsHO \n");
         return(1);
    }
    
    weightsIH = (double**) calloc(numberOfInputs, sizeof(double*));
    if(weightsIH==NULL) {
         fprintf(stderr,"MLP_NN could not allocate space for weightsIH \n");
         return(1);
    }
    for(k=0; k< numberOfInputs; k++) {
            weightsIH[k] = (double*) calloc(numberOfHidden, sizeof(double));
            
            if(weightsIH[k]==NULL) {
                    fprintf(stderr,"MLP_NN could not allocate space for weightsIH[k] k=%d \n",k);
                    return(1);
            }            
            
    }
    
    //************************************
    // set weights to random numbers 
 
     srand ( time(NULL) );
     for(int j = 0;j<numberOfHidden;j++)
     {
              randVal=((double)rand())/(double)RAND_MAX;
              weightsHO[j] = (double)(randVal - 0.5)/2;
              for(int i = 0;i<numberOfInputs;i++)
              {
                     randVal=((double)rand())/(double)RAND_MAX;
                     weightsIH[i][j] = (randVal - 0.5)/5;
                     printf("Weight = %f\n", weightsIH[i][j]);
              }
      }

   


]]>
</INIT_CODE> 


<MAIN_CODE>
<![CDATA[ 




for(ii = MIN_AVAIL(); ii>0; ii--) {  
        
       
         IT_IN(0);
         IT_IN(1);
         
      //   theVector=INVEC(0,0);
      
        theVector=x(0);
         sum=0;
        for(i=0; i< theVector.length; i++) {
        
            
           //   sum=sum+theVector.vector_P[i];
          //    printf("MLP_NN:%d    %f \n", i,theVector.vector_P[i]);
               if(theVector.vector_P[i]==0) theVector.vector_P[i]=-1;
           //    printf("MLP_NN:%d    %f \n", i,theVector.vector_P[i]);
           
            
        }
        
         
         fprintf(stderr,"MLP_NN desired=%f\n",desired(0));
         if(desired(0)==0) desiredbp=-1;
         else
                            desiredbp=1;
                            
                            
        for(i=0; i< theVector.length; i++) {
        
            
            
               printf("MLP_NN VEC :%d    %f \n", i,theVector.vector_P[i]);              
                
             
            
        }
          printf("MLP_NN:desired     %f \n", desiredbp);                    
         
         if(theVector.length != numberOfInputs-1) {
             fprintf(stderr,"MLP_NN input vector length not equal to numberOfInputs-1 %d:%d\n",theVector.length,numberOfInputs);
             return(1);
         
         } 
       /*
        * This is just to show how to access the vector elements
        */
        
        sum=0;
        for(i=0; i< theVector.length; i++) {
        
            
              sum=sum+theVector.vector_P[i];
         //     printf("MLP_NN:%d    %f \n", i,theVector.vector_P[i]);
           
           
            
        }
        for(i = 0;i<numberOfHidden;i++)
        {
	             hiddenVal[i] = 0.0;

                 for(int j = 0;j<numberOfInputs;j++)
                 {
	//                    hiddenVal[i] = hiddenVal[i] + (trainInputs[patNum][j] * weightsIH[j][i]);
	                      if(j==numberOfInputs-1) {
	                           // bias 
	                           hiddenVal[i] = hiddenVal[i] +   weightsIH[j][i];
	                      } else {
	                          hiddenVal[i] = hiddenVal[i] + (theVector.vector_P[j] * weightsIH[j][i]);
	                      }
                 }

                 hiddenVal[i] = tanh(hiddenVal[i]);
         }
         //calculate the output of the network
         //the output neuron is linear
         outPred = 0.0;

         for(i = 0;i<numberOfHidden;i++)
         {
                 outPred = outPred + hiddenVal[i] * weightsHO[i];
         }
         //calculate the error
         
         errThisPat = outPred - desiredbp;
         
         
         //************************************
         //adjust the weights hidden-output
         //void WeightChangesHO(void)
 
         for( k = 0;k<numberOfHidden;k++)
         {
                  weightChange = LR_HO * errThisPat * hiddenVal[k];
                  weightsHO[k] = weightsHO[k] - weightChange;

                   //regularisation on the output weights
                   if (weightsHO[k] < -5)
                   {
                          weightsHO[k] = -5;
                    }
                    else if (weightsHO[k] > 5)
                    {
                          weightsHO[k] = 5;
                    }
          }

         //************************************
         // adjust the weights input-hidden
         //void WeightChangesIH(void)
 

          for( i = 0;i<numberOfHidden;i++)
          {
                for(  k = 0;k<numberOfInputs;k++)
                {
                      xx = 1 - (hiddenVal[i] * hiddenVal[i]);
                      xx = xx * weightsHO[i] * errThisPat * LR_IH;
                  //    xx = xx * trainInputs[patNum][k];
                      if(k==numberOfInputs-1) {
	                           // bias 
	                           xx=xx;
	                   } else {
                            xx = xx * theVector.vector_P[k];
                       }
                      
                      
                      weightChange = xx;
                      weightsIH[k][i] = weightsIH[k][i] - weightChange;
                 }
          }

         
   
           /*
	    * ready output buffer for sample
	    * check for overflow
	    */
	   if(IT_OUT(0)) {
				KrnOverflow("MLP_NN",0);
				return(99);
	   }
	   /*
	    * output the sample
	    */
	   error(0)=errThisPat;
	   
	   /*
	    * ready output buffer for sample
	    * check for overflow
	    */
	   if(IT_OUT(1)) {
				KrnOverflow("MLP_NN",0);
				return(99);
	   }
	    dest(0)=outPred;
	   


}
    

]]>
</MAIN_CODE> 

<WRAPUP_CODE>
<![CDATA[ 
#if 1111
    if(hiddenVal) {
         free(hiddenVal);
    
    }
    if(weightsHO) {
         free(weightsHO);
    
    }
    for(k=0; k<numberOfInputs ; k++) {
           free(weightsIH[k]); 
    
    }
    free(weightsIH);
#endif    

]]>
</WRAPUP_CODE> 



</BLOCK> 

